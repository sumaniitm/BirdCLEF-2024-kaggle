{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":8078683,"sourceType":"datasetVersion","datasetId":4767916},{"sourceId":8236972,"sourceType":"datasetVersion","datasetId":4885707},{"sourceId":8325384,"sourceType":"datasetVersion","datasetId":4945035}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"!pip install duckdb --no-index --find-links=file:///kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install polars[numpy,pandas,pyarrow] --no-index --find-links=file:///kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T13:01:50.197020Z","iopub.execute_input":"2024-04-26T13:01:50.197469Z","iopub.status.idle":"2024-04-26T13:02:23.019628Z","shell.execute_reply.started":"2024-04-26T13:01:50.197433Z","shell.execute_reply":"2024-04-26T13:02:23.017987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import duckdb as dd\nimport polars as pl\nimport os\nimport glob\nimport shutil\nimport zipfile\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nimport seaborn as sns\n#!pip install plotly\nimport plotly.express as px\nimport librosa\nfrom IPython.display import Audio\nimport pickle\nfrom joblib import dump, load\nfrom pathlib import Path\n#!pip install -U imbalanced-learn\nfrom imblearn.over_sampling import RandomOverSampler\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2024-05-11T08:23:55.211608Z","iopub.execute_input":"2024-05-11T08:23:55.211997Z","iopub.status.idle":"2024-05-11T08:23:57.952113Z","shell.execute_reply.started":"2024-05-11T08:23:55.211963Z","shell.execute_reply":"2024-05-11T08:23:57.951088Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def audio_waveframe(file_path):\n    # Load the audio file\n    audio_data, sampling_rate = librosa.load(file_path)\n    # Calculate the duration of the audio file\n    duration = len(audio_data) / sampling_rate\n    # Create a time array for plotting\n    time = np.arange(0, duration, 1/sampling_rate)\n    # Plot the waveform\n    plt.figure(figsize=(30, 4))\n    plt.plot(time, audio_data, color='blue')\n    plt.title('Audio Waveform')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plot = plt.show()\n    return plot\n\ndef spectrogram(file_path):\n    # Compute the short-time Fourier transform (STFT)\n    n_fft = 500  # Number of FFT points 2048\n    hop_length = 50  # Hop length for STFT 512\n    audio_data, sampling_rate = librosa.load(file_path)\n    stft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\n    # Convert the magnitude spectrogram to decibels (log scale)\n    spectrogram = librosa.amplitude_to_db(np.abs(stft))\n    # Plot the spectrogram\n    plt.figure(figsize=(30, 6))\n    librosa.display.specshow(spectrogram, sr=sampling_rate, hop_length=hop_length, x_axis='time', y_axis='linear')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('Spectrogram')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Frequency (Hz)')\n    plt.tight_layout()\n    plot = plt.show()\n    return plot\n\ndef audio_analysis(file_path):\n    aw = audio_waveframe(file_path)\n    spg = spectrogram(file_path)\n    return aw, spg","metadata":{"execution":{"iopub.status.busy":"2024-05-11T08:23:59.967114Z","iopub.execute_input":"2024-05-11T08:23:59.967741Z","iopub.status.idle":"2024-05-11T08:23:59.981329Z","shell.execute_reply.started":"2024-05-11T08:23:59.967691Z","shell.execute_reply":"2024-05-11T08:23:59.980114Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# meta_data = pl.read_csv('/kaggle/input/birdclef-2024/train_metadata.csv', low_memory=True)\n# meta_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:21.247516Z","iopub.execute_input":"2024-05-11T07:42:21.247932Z","iopub.status.idle":"2024-05-11T07:42:21.252445Z","shell.execute_reply.started":"2024-05-11T07:42:21.247901Z","shell.execute_reply":"2024-05-11T07:42:21.251261Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#[meta_data.filter((pl.col('primary_label')=='asbfly') & (pl.col('type')==\"['song']\")).select('filename')]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T13:38:03.525434Z","iopub.execute_input":"2024-04-26T13:38:03.525891Z","iopub.status.idle":"2024-04-26T13:38:03.536451Z","shell.execute_reply.started":"2024-04-26T13:38:03.525857Z","shell.execute_reply":"2024-04-26T13:38:03.534986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"audio_analysis('/kaggle/input/birdclef-2024/train_audio/asbfly/XC374520.ogg')\nAudio('/kaggle/input/birdclef-2024/train_audio/asbfly/XC374520.ogg')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T13:38:14.286907Z","iopub.execute_input":"2024-04-26T13:38:14.287345Z","iopub.status.idle":"2024-04-26T13:38:25.274672Z","shell.execute_reply.started":"2024-04-26T13:38:14.287309Z","shell.execute_reply":"2024-04-26T13:38:25.273362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"with open(\"/kaggle/input/extracted-features-pickle/extracted_features\", \"rb\") as file:\n    pickled_extracted_features = pickle.load(file)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-27T03:56:59.811203Z","iopub.execute_input":"2024-04-27T03:56:59.812340Z","iopub.status.idle":"2024-04-27T03:56:59.865009Z","shell.execute_reply.started":"2024-04-27T03:56:59.812295Z","shell.execute_reply":"2024-04-27T03:56:59.863784Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Path to the directory containing your audio dataset\ndataset_dir = '/kaggle/input/birdclef-2024/train_audio'\n# Initialize an empty dictionary to store the mapping between audio files and labels\nlabel_mapping = {}\n# Iterate over subdirectories (classes) in the dataset directory\nfor label in os.listdir(dataset_dir):\n    label_dir = os.path.join(dataset_dir, label)\n    # Check if the item in the dataset directory is a directory\n    if os.path.isdir(label_dir):\n        # Iterate over audio files in the subdirectory (class)\n        for audio_file in os.listdir(label_dir):\n            # Add the mapping between audio file path and label to the dictionary\n            audio_file_path = os.path.join(label_dir, audio_file)\n            label_mapping[audio_file_path] = label\n            \n# label_mapping\n\n# Create a list of tuples containing the audio file paths and labels\ndata = [(audio_file_path, label) for audio_file_path, label in label_mapping.items()]\n# Create a Pandas DataFrame from the list of tuples\nannotated_data = pd.DataFrame(data, columns=['audio_file_path', 'label'])\n\nlabel_encoder = LabelEncoder()\nannotated_data['encoded_label'] = label_encoder.fit_transform(annotated_data['label'])\n\nannotated_data.head(10)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:25.838247Z","iopub.execute_input":"2024-05-11T07:42:25.839008Z","iopub.status.idle":"2024-05-11T07:42:25.848097Z","shell.execute_reply.started":"2024-05-11T07:42:25.838974Z","shell.execute_reply":"2024-05-11T07:42:25.846904Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"\"# Path to the directory containing your audio dataset\\ndataset_dir = '/kaggle/input/birdclef-2024/train_audio'\\n# Initialize an empty dictionary to store the mapping between audio files and labels\\nlabel_mapping = {}\\n# Iterate over subdirectories (classes) in the dataset directory\\nfor label in os.listdir(dataset_dir):\\n    label_dir = os.path.join(dataset_dir, label)\\n    # Check if the item in the dataset directory is a directory\\n    if os.path.isdir(label_dir):\\n        # Iterate over audio files in the subdirectory (class)\\n        for audio_file in os.listdir(label_dir):\\n            # Add the mapping between audio file path and label to the dictionary\\n            audio_file_path = os.path.join(label_dir, audio_file)\\n            label_mapping[audio_file_path] = label\\n            \\n# label_mapping\\n\\n# Create a list of tuples containing the audio file paths and labels\\ndata = [(audio_file_path, label) for audio_file_path, label in label_mapping.items()]\\n# Create a Pandas DataFrame from the list of tuples\\nannotated_data = pd.DataFrame(data, columns=['audio_file_path', 'label'])\\n\\nlabel_encoder = LabelEncoder()\\nannotated_data['encoded_label'] = label_encoder.fit_transform(annotated_data['label'])\\n\\nannotated_data.head(10)\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"x = np.vstack(pickled_extracted_features)\ny = annotated_data['encoded_label']\n\nprint(x.shape)\nprint(y.shape)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:28.812808Z","iopub.execute_input":"2024-05-11T07:42:28.813185Z","iopub.status.idle":"2024-05-11T07:42:28.820081Z","shell.execute_reply.started":"2024-05-11T07:42:28.813158Z","shell.execute_reply":"2024-05-11T07:42:28.818947Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"x = np.vstack(pickled_extracted_features)\\ny = annotated_data['encoded_label']\\n\\nprint(x.shape)\\nprint(y.shape)\""},"metadata":{}}]},{"cell_type":"code","source":"# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:29.418622Z","iopub.execute_input":"2024-05-11T07:42:29.419027Z","iopub.status.idle":"2024-05-11T07:42:29.423858Z","shell.execute_reply.started":"2024-05-11T07:42:29.419000Z","shell.execute_reply":"2024-05-11T07:42:29.422710Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"ros = RandomOverSampler(random_state=42)\nfeatures_resampled, labels_resampled = ros.fit_resample(x, y)\n\nprint(features_resampled.shape)\nprint(labels_resampled.shape)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:30.215520Z","iopub.execute_input":"2024-05-11T07:42:30.215931Z","iopub.status.idle":"2024-05-11T07:42:30.222624Z","shell.execute_reply.started":"2024-05-11T07:42:30.215902Z","shell.execute_reply":"2024-05-11T07:42:30.221372Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'ros = RandomOverSampler(random_state=42)\\nfeatures_resampled, labels_resampled = ros.fit_resample(x, y)\\n\\nprint(features_resampled.shape)\\nprint(labels_resampled.shape)'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"unique_labels = labels_resampled.unique().sort()\n\nx_train, x_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:31.650409Z","iopub.execute_input":"2024-05-11T07:42:31.650815Z","iopub.status.idle":"2024-05-11T07:42:31.657386Z","shell.execute_reply.started":"2024-05-11T07:42:31.650785Z","shell.execute_reply":"2024-05-11T07:42:31.656268Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'unique_labels = labels_resampled.unique().sort()\\n\\nx_train, x_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"from sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\n\npoly_kernel_svm_clf = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5, probability=True))\n])\n\npoly_kernel_svm_clf.fit(x_train, y_train)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:32.352638Z","iopub.execute_input":"2024-05-11T07:42:32.353048Z","iopub.status.idle":"2024-05-11T07:42:32.360211Z","shell.execute_reply.started":"2024-05-11T07:42:32.353019Z","shell.execute_reply":"2024-05-11T07:42:32.359088Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'from sklearn.pipeline import Pipeline\\nfrom sklearn.svm import SVC\\nfrom sklearn.preprocessing import StandardScaler\\n\\npoly_kernel_svm_clf = Pipeline([\\n    (\"scaler\", StandardScaler()),\\n    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5, probability=True))\\n])\\n\\npoly_kernel_svm_clf.fit(x_train, y_train)'"},"metadata":{}}]},{"cell_type":"code","source":"# dump(poly_kernel_svm_clf, 'audio_classifier_svc_deg3poly_model.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T04:11:01.802597Z","iopub.execute_input":"2024-04-27T04:11:01.803926Z","iopub.status.idle":"2024-04-27T04:11:01.978911Z","shell.execute_reply.started":"2024-04-27T04:11:01.803861Z","shell.execute_reply":"2024-04-27T04:11:01.977447Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['audio_classifier_svc_deg3poly_model.joblib']"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrandom_forest_model = random_forest_classifier.fit(x_train, y_train)\n#y_predict = random_forest_model.predict(x_test)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:58:35.995932Z","iopub.execute_input":"2024-04-26T14:58:35.996407Z","iopub.status.idle":"2024-04-26T15:02:33.042032Z","shell.execute_reply.started":"2024-04-26T14:58:35.996375Z","shell.execute_reply":"2024-04-26T15:02:33.040792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_predict = poly_kernel_svm_clf.predict_proba(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:15:30.759518Z","iopub.execute_input":"2024-04-26T15:15:30.759951Z","iopub.status.idle":"2024-04-26T15:19:24.281099Z","shell.execute_reply.started":"2024-04-26T15:15:30.759919Z","shell.execute_reply":"2024-04-26T15:19:24.279630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"roc_score = roc_auc_score(y_test, y_predict_rf, multi_class='ovo', average='macro', labels=unique_labels)\nprint(\"ROC AUC Score:\", roc_score)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:03:25.441654Z","iopub.execute_input":"2024-04-26T15:03:25.442258Z","iopub.status.idle":"2024-04-26T15:03:51.157650Z","shell.execute_reply.started":"2024-04-26T15:03:25.442211Z","shell.execute_reply":"2024-04-26T15:03:51.156371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"roc_score = roc_auc_score(y_test, y_predict, multi_class='ovo', average='macro', labels=unique_labels)\nprint(\"ROC AUC Score:\", roc_score)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:20:14.155885Z","iopub.execute_input":"2024-04-26T15:20:14.156419Z","iopub.status.idle":"2024-04-26T15:20:40.479531Z","shell.execute_reply.started":"2024-04-26T15:20:14.156373Z","shell.execute_reply":"2024-04-26T15:20:40.478416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_deg3poly_model = load('/kaggle/input/newly-trained-5sec-model-and-features/svc_deg3_poly_on_5sec_features.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:36.503044Z","iopub.execute_input":"2024-05-11T07:42:36.503452Z","iopub.status.idle":"2024-05-11T07:42:37.969604Z","shell.execute_reply.started":"2024-05-11T07:42:36.503422Z","shell.execute_reply":"2024-05-11T07:42:37.968505Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"config = {}\nTest = False\n\nif Test:\n    config['root_file_path'] = '/kaggle/input/birdclef-2024/unlabeled_soundscapes/'\n    config['start'] = 7000\n    config['end'] = 8200\n    filenames_with_path = glob.glob(f\"{config['root_file_path']}*.ogg\")\n    filenames = [os.path.basename(filename) for filename in filenames_with_path][config['start']:config['end']]\n    print(len(filenames))\nelse:\n    config['root_file_path'] = '/kaggle/input/birdclef-2024/test_soundscapes/'\n    filenames_with_path = glob.glob(f\"{config['root_file_path']}*.ogg\")\n    filenames = [os.path.basename(filename) for filename in filenames_with_path]\n    print(len(filenames))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T08:24:26.025694Z","iopub.execute_input":"2024-05-11T08:24:26.026618Z","iopub.status.idle":"2024-05-11T08:24:26.038623Z","shell.execute_reply.started":"2024-05-11T08:24:26.026575Z","shell.execute_reply":"2024-05-11T08:24:26.037445Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\nchunk_feature_dict = {}\n\nfor file in tqdm(filenames):\n    full_path = config['root_file_path']+file\n    audio, sample_rate = librosa.load(path=full_path, sr=32000)\n    cur_file = file.replace('.ogg','')\n    samples_per_segment = sample_rate * 5\n    if len(audio) > 7680000:\n        total_samples = 7680000\n    else:\n        total_samples = len(audio)\n        \n    for i in range(0, total_samples+160000, samples_per_segment):\n        if i + samples_per_segment <= total_samples:\n            segment = audio[i:i + samples_per_segment]\n            chunk = cur_file+'_'+str(int((i/32000)+5))\n            mfccs = librosa.feature.mfcc(y=segment, sr=32000, n_mfcc=40)\n            flattened_features = (np.mean(mfccs.T, axis=0)).reshape(1, -1)\n            chunk_feature_dict[chunk] = np.ascontiguousarray(flattened_features)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T07:42:50.836350Z","iopub.execute_input":"2024-05-11T07:42:50.836763Z","iopub.status.idle":"2024-05-11T08:14:46.324495Z","shell.execute_reply.started":"2024-05-11T07:42:50.836733Z","shell.execute_reply":"2024-05-11T08:14:46.322931Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 1200/1200 [31:55<00:00,  1.60s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"meta_data = pl.read_csv('../input/birdclef-2024/train_metadata.csv', low_memory=True)\nbird_cols = list(meta_data['primary_label'].unique().sort())\n\nsubmit = pd.read_csv(\"/kaggle/input/birdclef-2024/sample_submission.csv\")\nsubmit['row_id'] = 'samples'\n\nsubmit","metadata":{"execution":{"iopub.status.busy":"2024-05-11T08:16:40.038147Z","iopub.execute_input":"2024-05-11T08:16:40.038822Z","iopub.status.idle":"2024-05-11T08:16:40.316983Z","shell.execute_reply.started":"2024-05-11T08:16:40.038788Z","shell.execute_reply":"2024-05-11T08:16:40.315876Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"    row_id    asbfly   ashdro1   ashpri1   ashwoo2   asikoe2   asiope1  \\\n0  samples  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495   \n1  samples  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495   \n2  samples  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495   \n\n    aspfly1   aspswi1   barfly1  ...   whbwoo2   whcbar1   whiter2    whrmun  \\\n0  0.005495  0.005495  0.005495  ...  0.005495  0.005495  0.005495  0.005495   \n1  0.005495  0.005495  0.005495  ...  0.005495  0.005495  0.005495  0.005495   \n2  0.005495  0.005495  0.005495  ...  0.005495  0.005495  0.005495  0.005495   \n\n    whtkin2    woosan   wynlau1   yebbab1   yebbul3   zitcis1  \n0  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495  \n1  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495  \n2  0.005495  0.005495  0.005495  0.005495  0.005495  0.005495  \n\n[3 rows x 183 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>asbfly</th>\n      <th>ashdro1</th>\n      <th>ashpri1</th>\n      <th>ashwoo2</th>\n      <th>asikoe2</th>\n      <th>asiope1</th>\n      <th>aspfly1</th>\n      <th>aspswi1</th>\n      <th>barfly1</th>\n      <th>...</th>\n      <th>whbwoo2</th>\n      <th>whcbar1</th>\n      <th>whiter2</th>\n      <th>whrmun</th>\n      <th>whtkin2</th>\n      <th>woosan</th>\n      <th>wynlau1</th>\n      <th>yebbab1</th>\n      <th>yebbul3</th>\n      <th>zitcis1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>samples</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>...</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>samples</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>...</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>samples</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>...</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n      <td>0.005495</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 183 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for file_name, feature_set in tqdm(chunk_feature_dict.items()):\n    df = pd.DataFrame(svc_deg3poly_model.predict_proba(feature_set), columns=bird_cols)\n    df.insert(loc=0, column='row_id', value=file_name)\n    submit = pd.concat([submit,df]).reset_index(drop=True)\n    \ni = submit[(submit.row_id == 'samples')].index\nsubmit = submit.drop(i).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T08:16:42.953268Z","iopub.execute_input":"2024-05-11T08:16:42.953706Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 16%|█▋        | 9360/57251 [04:53<27:24, 29.12it/s]","output_type":"stream"}]},{"cell_type":"code","source":"submit.head(100)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T04:35:48.640382Z","iopub.execute_input":"2024-05-11T04:35:48.641047Z","iopub.status.idle":"2024-05-11T04:35:48.654761Z","shell.execute_reply.started":"2024-05-11T04:35:48.640994Z","shell.execute_reply":"2024-05-11T04:35:48.653898Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [row_id, asbfly, ashdro1, ashpri1, ashwoo2, asikoe2, asiope1, aspfly1, aspswi1, barfly1, barswa, bcnher, bkcbul1, bkrfla1, bkskit1, bkwsti, bladro1, blaeag1, blakit1, blhori1, blnmon1, blrwar1, bncwoo3, brakit1, brasta1, brcful1, brfowl1, brnhao1, brnshr, brodro1, brwjac1, brwowl1, btbeat1, bwfshr1, categr, chbeat1, cohcuc1, comfla1, comgre, comior1, comkin1, commoo3, commyn, compea, comros, comsan, comtai1, copbar1, crbsun2, cregos1, crfbar1, crseag1, dafbab1, darter2, eaywag1, emedov2, eucdov, eurbla2, eurcoo, forwag1, gargan, gloibi, goflea1, graher1, grbeat1, grecou1, greegr, grefla1, grehor1, grejun2, grenig1, grewar3, grnsan, grnwar1, grtdro1, gryfra, grynig2, grywag, gybpri1, gyhcaf1, heswoo1, hoopoe, houcro1, houspa, inbrob1, indpit1, indrob1, indrol2, indtit1, ingori1, inpher1, insbab1, insowl1, integr, isbduc1, jerbus2, junbab2, junmyn1, junowl1, kenplo1, ...]\nIndex: []\n\n[0 rows x 183 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>asbfly</th>\n      <th>ashdro1</th>\n      <th>ashpri1</th>\n      <th>ashwoo2</th>\n      <th>asikoe2</th>\n      <th>asiope1</th>\n      <th>aspfly1</th>\n      <th>aspswi1</th>\n      <th>barfly1</th>\n      <th>...</th>\n      <th>whbwoo2</th>\n      <th>whcbar1</th>\n      <th>whiter2</th>\n      <th>whrmun</th>\n      <th>whtkin2</th>\n      <th>woosan</th>\n      <th>wynlau1</th>\n      <th>yebbab1</th>\n      <th>yebbul3</th>\n      <th>zitcis1</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 183 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/birdclef-2024/sample_submission.csv\")\nassert set(sample_submission.columns) == set(submit.columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T04:35:50.242322Z","iopub.execute_input":"2024-05-11T04:35:50.243203Z","iopub.status.idle":"2024-05-11T04:35:50.255806Z","shell.execute_reply.started":"2024-05-11T04:35:50.243168Z","shell.execute_reply":"2024-05-11T04:35:50.254015Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T04:35:51.468688Z","iopub.execute_input":"2024-05-11T04:35:51.469043Z","iopub.status.idle":"2024-05-11T04:35:51.504299Z","shell.execute_reply.started":"2024-05-11T04:35:51.469018Z","shell.execute_reply":"2024-05-11T04:35:51.503085Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}